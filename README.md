# SECOM-ML-project Example

This repository contains a classroom practice notebook from a machine learning course.

## ğŸ“˜ Overview

The notebook demonstrates a modeling workflow starting **after data imputation**, including:

- ğŸ” **Feature reduction** using Boruta
- âš–ï¸ **Balancing** with SMOTE, ADASYN, RandomOverSampler
- ğŸ“ **Scaling** via StandardScaler and MinMaxScaler
- ğŸ¤– **Modeling** using multiple algorithms such as:
  - Random Forest
  - Logistic Regression
  - KNN
  - LDA
  - SVM (with optional normality test and transformation)

## ğŸ›  Function-Based Design

This notebook adopts a modular design using Python functions for flexible experimentation:

1. ğŸ”§ Various preprocessing methods (imputers, scalers, balancers, models) are stored in **dictionaries**.
2. âš™ï¸ The core **modeling process** is encapsulated in a reusable function.
3. ğŸ” Another function uses **for-loops and recursion** to iterate through all combinations of techniques.
4. ğŸ“Š Each result is recorded and optionally written to CSV, avoiding duplication by checking identifiers.

## ğŸ“„ Output

- A summary table of evaluation metrics for each model configuration.
- Exported results saved as `model_comparison_results.csv`.

## ğŸ§ª Key Libraries Used

- `scikit-learn`
- `imbalanced-learn`
- `boruta_py`
- `pandas`, `numpy`

---

This example serves as a reference for building standardized, reproducible modeling pipelines in real-world machine learning workflows.
